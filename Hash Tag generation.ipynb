{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39425971-e21c-447f-8da6-a891006f0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from env import load_env\n",
    "from typing import Tuple\n",
    "\n",
    "def load_project_and_location() -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Loads the project and location from the environment.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[str, str]: A tuple containing the project and location strings.\n",
    "    \"\"\"\n",
    "    project, location = load_env()\n",
    "    return project, location\n",
    "\n",
    "def generate(prompt: str, parameters: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generates anything for a the given text using prompt and a language model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text for which a summary needs to be generated.\n",
    "        prompt (str): The prompt to be used for text generation.\n",
    "        parameters (dict): A dictionary of generation parameters.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text summary.\n",
    "    \"\"\"\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(prompt, **parameters)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb512b7d-0bd3-4c91-b067-b4cfc78bba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Tokenize the hashtags of this text: Attending an inspiring tech conference with industry leaders üöÄüíº \n",
    "The hashtags in this text are: \n",
    "#TechConference \n",
    "#Networking \n",
    "#Innovation \n",
    "#ProfessionalGrowth\n",
    "\n",
    "Tokenize the hashtags of this text: Just read a fascinating article about the potential of LLMs in revolutionizing natural language understanding and generation. ü§Øüìö\n",
    "The hashtags in this text are: \n",
    "#AI \n",
    "#NLP \n",
    "#MachineLearning\n",
    "#LLM\n",
    "#GenAI\n",
    "\n",
    "Tokenize the hashtags of this text: Exploring the ethical implications of deploying Large Language Models in decision-making processes. ü§îü§Ø\n",
    "The hashtags in this text are: \n",
    "#EthicalAI \n",
    "#AIResponsibility \n",
    "#TechEthics\n",
    "\n",
    "Tokenize the hashtags of this text: Deep learning models are revolutionizing computer vision. Impressive object recognition and image generation capabilities! üì∑üëÅÔ∏è\n",
    "The hashtags in this text are: \n",
    "#ComputerVision \n",
    "#DeepLearning \n",
    "#AIinVision\n",
    "\n",
    "Tokenize the hashtags of this text: Generative AI has introduced a paradigm shift for digital transformation, and harnessing its power in a responsible way can unlock new possibilities. But many organizations are unable to activate data and AI due to fragmented data systems for analytics, AI, and machine learning, which aren‚Äôt designed to work together and instead slow innovation. Join this session to learn how leaders are accelerating transformation with Google‚Äôs data and AI cloud.\n",
    "The hashtags in this text are:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498fd8c7-35cb-4368-84de-2794dc9f77b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Generated hash_tags are:\n",
      "#AI \n",
      "#Data \n",
      "#MachineLearning \n",
      "#DigitalTransformation \n",
      "#GoogleCloud\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"max_output_tokens\": 128,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "\n",
    "hash_tags = generate(prompt, parameters)\n",
    "print(f\"The Generated hash_tags are:\\n{hash_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3b72a-fd8c-4249-a489-e48c55e9a4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
